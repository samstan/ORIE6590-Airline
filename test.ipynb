{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing open ai gym and the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import airline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function for evaluating the model on a given environment for a specified number of episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env, numiters):\n",
    "    rewards = []\n",
    "    for j in range(numiters):\n",
    "        env.reset()\n",
    "        tot_reward = 0\n",
    "        for i in range(env.tau):\n",
    "            _, reward, _, _ = env.step(model(env), i)\n",
    "            tot_reward += reward\n",
    "        rewards.append(tot_reward)\n",
    "    return np.mean(rewards), np.std(rewards)\n",
    "\n",
    "# Model is the random policy\n",
    "def policy(env):\n",
    "    return env.action_space.sample()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the configuration for the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray([[1, 1, 0,0,0,0], [ 0,0, 1, 1, 1, 1], [ 0,0, 0,0, 1, 1] ])\n",
    "tau = 23\n",
    "P = np.ones((tau, A.shape[1]))/3\n",
    "c = [5, 5, 5]\n",
    "f = range(10, 16)\n",
    "CONFIG = {'A': A, 'f': f, 'P': P, 'starting_state': c , 'tau': tau}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an instance of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Airline-v0', config=CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6]\n",
      "MultiDiscrete([2 2 2 2 2 2])\n",
      "MultiDiscrete([6 6 6])\n"
     ]
    }
   ],
   "source": [
    "print(env.state)\n",
    "print(env.action_space)\n",
    "print(env.observation_space) # openAI calles states observations :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 0, 0]), 0, False, {})\n",
      "***\n",
      "(array([3, 2, 3]), 11, False, {})\n"
     ]
    }
   ],
   "source": [
    "env.state = [1,0, 0]\n",
    "print(env.step(np.asarray([1,1, 1, 1, 1, 1]), 5))\n",
    "print('***')\n",
    "env.state = [3, 3, 3]\n",
    "print(env.step([1,1, 1, 1, 1, 1], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test sample uniformly from action space at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating randomized policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "e = 23\n",
    "rewards = []\n",
    "for j in range(e):\n",
    "    env.reset()\n",
    "    tot_reward = 0\n",
    "    for i in range(tau):\n",
    "        _, reward, _, _ = env.step(env.action_space.sample(), i)\n",
    "        tot_reward += reward\n",
    "    rewards.append(tot_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the mean and standard deviation of the estimate (105.38, 8.546086823804215)\n"
     ]
    }
   ],
   "source": [
    "print('Here is the mean and standard deviation of the estimate ' + str(evaluate(policy, env, 50)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
